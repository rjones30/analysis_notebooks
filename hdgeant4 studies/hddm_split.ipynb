{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4069294d-b2c1-496c-b275-011810bb9c50",
   "metadata": {},
   "source": [
    "# Large hddm file splitter\n",
    "Sometimes it is useful for the sake of parallel processing efficiency to split up a large hddm file into a series of smaller ones. This notebook demonstrates a parallel process for accomplishing this splitting using dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9fe7ae5-f8e9-44c4-923b-94a15076af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluex import hddm_s\n",
    "import dask.distributed\n",
    "import dask\n",
    "client = dask.distributed.Client(n_workers=30, threads_per_worker=1, dashboard_address='localhost:8789')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb652d35-1b36-4bbd-8a60-c7aa261fd023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicer(infile, slicesize, sliceindex, count=1):\n",
    "    \"\"\"\n",
    "    Reads up to slicesize events starting at event sliceindex*slicesize\n",
    "    from input hddm file infile and copies them to a new output file with\n",
    "    a name generated from the name of infile with a subscript sliceindex.\n",
    "    Return value is the number of events copied, or -1 for error. Output\n",
    "    files are left on the /local filesystem.\n",
    "    \"\"\"\n",
    "    basepath = infile.split(\".hddm\")[0]\n",
    "    if basepath == infile:\n",
    "        return -1\n",
    "    hin = hddm_s.istream(infile)\n",
    "    hin.skip(sliceindex * slicesize)\n",
    "    ncopied = 0\n",
    "    for islice in range(count):\n",
    "        outfile = f\"/local/{basepath.split('/')[-1]}_{sliceindex + islice}.hddm\"\n",
    "        hout = hddm_s.ostream(outfile)\n",
    "        for rec in hin:\n",
    "            hout.write(rec)\n",
    "            ncopied += 1\n",
    "            if ncopied % slicesize == 0:\n",
    "                break\n",
    "    return ncopied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3ed6db-383a-49ed-b38e-5346daad8494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final event count is 500000\n"
     ]
    }
   ],
   "source": [
    "infile = \"root://cn445.storrs.hpc.uconn.edu/Gluex/resilient/simulation/KLFbeam-8-2024/forced_500k.hddm\"\n",
    "slicesize = 1000\n",
    "slicecount = 500\n",
    "results = [dask.delayed(slicer)(infile, slicesize, i*25, 25) for i in range(slicecount//25)]\n",
    "collection = dask.delayed(sum)(results)\n",
    "final_count = collection.compute()\n",
    "print(\"final event count is\", final_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52ce7d-8247-4cb5-a20c-96f7c08b762d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
